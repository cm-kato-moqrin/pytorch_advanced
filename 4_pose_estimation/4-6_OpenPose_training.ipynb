{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
    "\n",
    "# ITOPのファイルパスリスト作成\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(\n",
    "    rootpath=\"./data/\")\n",
    "\n",
    "# Dataset作成\n",
    "# 訓練データ\n",
    "train_dataset = COCOkeypointsDataset(\n",
    "    train_img_list, train_mask_list, train_meta_list, phase=\"train\", transform=DataTransform())\n",
    "\n",
    "# 検証データ\n",
    "val_dataset = COCOkeypointsDataset(\n",
    "    val_img_list, val_mask_list, val_meta_list, phase=\"val\", transform=DataTransform())\n",
    "\n",
    "# DataLoader作成\n",
    "# batch_size = 128\n",
    "batch_size = 16\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "   val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(train_img_list[24])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(val_img_list[240])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask_list[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_list[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークモデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "\n",
    "# 学習済みモデルと本章のモデルでネットワークの層の名前が違うので、対応させてロードする\n",
    "# モデルの定義\n",
    "net = OpenPoseNet()\n",
    "# マルチGPUを使う場合\n",
    "# net = torch.nn.DataParallel(OpenPoseNet())\n",
    "\n",
    "# 学習済みパラメータをロードする\n",
    "net_weights = torch.load(\n",
    "    './weights/pose_model_scratch.pth', map_location={'cuda:0': 'cpu'})\n",
    "keys = list(net_weights.keys())\n",
    "\n",
    "weights_load = {}\n",
    "\n",
    "# ロードした内容を、本書で構築したモデルの\n",
    "# パラメータ名net.state_dict().keys()にコピーする\n",
    "for i in range(len(keys)):\n",
    "    weights_load[list(net.state_dict().keys())[i]\n",
    "                 ] = net_weights[list(keys)[i]]\n",
    "\n",
    "# コピーした内容をモデルに与える\n",
    "state = net.state_dict()\n",
    "state.update(weights_load)\n",
    "net.load_state_dict(state)\n",
    "\n",
    "# ネットワークを訓練モードにする\n",
    "net.train()\n",
    "\n",
    "print('ネットワーク設定完了：学習済みの重みをロードし、訓練モードに設定しました')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の設定\n",
    "class OpenPoseLoss(nn.Module):\n",
    "    \"\"\"OpenPoseの損失関数のクラスです。\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "\n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        \"\"\"\n",
    "        損失関数の計算。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        saved_for_loss : OpenPoseNetの出力(リスト)\n",
    "\n",
    "        heatmap_target : [num_batch, 19, 46, 46]\n",
    "            正解の部位のアノテーション情報\n",
    "\n",
    "        heatmap_mask : [num_batch, 19, 46, 46]\n",
    "            heatmap画像のmask\n",
    "\n",
    "        paf_target : [num_batch, 38, 46, 46]\n",
    "            正解のPAFのアノテーション情報\n",
    "\n",
    "        paf_mask : [num_batch, 38, 46, 46]\n",
    "            PAF画像のmask\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loss : テンソル\n",
    "            損失の値\n",
    "        \"\"\"\n",
    "\n",
    "        total_loss = 0\n",
    "        # ステージごとに計算します\n",
    "        for j in range(6):\n",
    "\n",
    "            # PAFsとheatmapsにおいて、マスクされている部分（paf_mask=0など）は無視させる\n",
    "            # PAFs\n",
    "            pred1 = saved_for_loss[2 * j] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "\n",
    "            # heatmaps\n",
    "            pred2 = saved_for_loss[2 * j + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float()*heat_mask\n",
    "\n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
    "                F.mse_loss(pred2, gt2, reduction='mean')\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "\n",
    "criterion = OpenPoseLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2,\n",
    "                      momentum=0.9,\n",
    "                      weight_decay=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenPoseモデルのネットワーク構成を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最適化手法の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファインチューニングで学習させるパラメータを、変数params_to_updateの1～3に格納する\n",
    "\n",
    "params_to_update_1 = []\n",
    "params_to_update_2 = []\n",
    "params_to_update_3 = []\n",
    "\n",
    "# 学習させる層のパラメータ名を指定\n",
    "update_param_names_1 = [\"model0.model\"]\n",
    "update_param_names_2 = [\"model1_1.0.weight\",\n",
    "                        \"model2_1.0.weight\", \"model1_2.0.weight\", \"model2_2.0.weight\"]\n",
    "update_param_names_3 = [\"model6_2.10.weight\", \"model6_2.12.weight\"]\n",
    "\n",
    "# パラメータごとに各リストに格納する\n",
    "for name, param in net.named_parameters():\n",
    "    if update_param_names_1[0] in name:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_1.append(param)\n",
    "        print(\"params_to_update_1に格納：\", name)\n",
    "\n",
    "    elif name in update_param_names_2:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_2.append(param)\n",
    "        print(\"params_to_update_2に格納：\", name)\n",
    "\n",
    "    elif name in update_param_names_3:\n",
    "        param.requires_grad = True\n",
    "        params_to_update_3.append(param)\n",
    "        print(\"params_to_update_3に格納：\", name)\n",
    "\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "        print(\"勾配計算なし。学習しない：\", name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化手法の設定 今回は特に学習率を層で変更したりスケジューラを設定する必要はなかった\n",
    "optimizer = optim.SGD([\n",
    "    {'params': params_to_update_1, 'lr': 1},\n",
    "    {'params': params_to_update_2, 'lr': 1},\n",
    "    {'params': params_to_update_3, 'lr': 1}\n",
    "], momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習・検証を実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を描画するためのリスト\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(\"using\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs = len(dataloaders_dict[\"val\"].dataset)\n",
    "\n",
    "    batch_size = dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                optimizer.zero_grad()\n",
    "                print('（train）')\n",
    "            else:\n",
    "\n",
    "                net.eval()   # モデルを検証モードに\n",
    "                print('-------------')\n",
    "                print('（val）')\n",
    "            \n",
    "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
    "            if (epoch == 0) and (phase == 'train'):\n",
    "                continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for imges, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
    "                # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n",
    "                if imges.size()[0] == 1:\n",
    "                    continue\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                imges = imges.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # (out6_1, out6_2)は使わないので _ で代替\n",
    "                    _, saved_for_loss = net(imges)\n",
    "\n",
    "                    loss = criterion(saved_for_loss, heatmap_target,\n",
    "                                     heat_mask, paf_target, paf_mask)\n",
    "                    del saved_for_loss\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        if (iteration % 20 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('イテレーション {} || Loss: {:.4f} || 20iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item()/batch_size, duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n",
    "        \n",
    "        train_losses.append(epoch_train_loss/num_train_imgs)\n",
    "        val_losses.append(epoch_val_loss/num_val_imgs)\n",
    "        \n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "    # 最後のネットワークを保存する\n",
    "    torch.save(net.state_dict(), 'weights/weights_itop_fine_tuning_' + datetime.datetime.today().strftime(\"%Y_%m_%d_%H_%M_%S\") \n",
    "               + '.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス： cuda:0\n",
      "-------------\n",
      "Epoch 1/2\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 10 || Loss: 0.0094 || 10iter: 113.7127 sec.\n",
      "イテレーション 20 || Loss: 0.0082 || 10iter: 90.4145 sec.\n",
      "イテレーション 30 || Loss: 0.0069 || 10iter: 88.4890 sec.\n",
      "イテレーション 40 || Loss: 0.0058 || 10iter: 90.9961 sec.\n",
      "イテレーション 50 || Loss: 0.0050 || 10iter: 90.8274 sec.\n",
      "イテレーション 60 || Loss: 0.0042 || 10iter: 89.7553 sec.\n",
      "イテレーション 70 || Loss: 0.0038 || 10iter: 91.1155 sec.\n",
      "イテレーション 80 || Loss: 0.0031 || 10iter: 91.3307 sec.\n",
      "イテレーション 90 || Loss: 0.0027 || 10iter: 91.7214 sec.\n",
      "イテレーション 100 || Loss: 0.0026 || 10iter: 92.2645 sec.\n",
      "イテレーション 110 || Loss: 0.0023 || 10iter: 91.7421 sec.\n",
      "イテレーション 120 || Loss: 0.0020 || 10iter: 90.7930 sec.\n",
      "イテレーション 130 || Loss: 0.0020 || 10iter: 91.3045 sec.\n",
      "イテレーション 140 || Loss: 0.0019 || 10iter: 91.6105 sec.\n",
      "イテレーション 150 || Loss: 0.0016 || 10iter: 90.2619 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:0.0043 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  1462.0789 sec.\n",
      "-------------\n",
      "Epoch 2/2\n",
      "-------------\n",
      "（train）\n",
      "イテレーション 160 || Loss: 0.0017 || 10iter: 64.3399 sec.\n",
      "イテレーション 170 || Loss: 0.0017 || 10iter: 91.2324 sec.\n",
      "イテレーション 180 || Loss: 0.0015 || 10iter: 92.3138 sec.\n",
      "イテレーション 190 || Loss: 0.0015 || 10iter: 90.3904 sec.\n",
      "イテレーション 200 || Loss: 0.0015 || 10iter: 90.9617 sec.\n",
      "イテレーション 210 || Loss: 0.0016 || 10iter: 91.2119 sec.\n",
      "イテレーション 220 || Loss: 0.0014 || 10iter: 90.6868 sec.\n",
      "イテレーション 230 || Loss: 0.0016 || 10iter: 90.8710 sec.\n",
      "イテレーション 240 || Loss: 0.0017 || 10iter: 90.3973 sec.\n",
      "イテレーション 250 || Loss: 0.0014 || 10iter: 90.8158 sec.\n",
      "イテレーション 260 || Loss: 0.0012 || 10iter: 92.8508 sec.\n",
      "イテレーション 270 || Loss: 0.0012 || 10iter: 91.9698 sec.\n",
      "イテレーション 280 || Loss: 0.0015 || 10iter: 90.8905 sec.\n",
      "イテレーション 290 || Loss: 0.0011 || 10iter: 91.2742 sec.\n",
      "イテレーション 300 || Loss: 0.0012 || 10iter: 91.0789 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:0.0015 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  1437.0403 sec.\n"
     ]
    }
   ],
   "source": [
    "# 学習・検証を実行する\n",
    "num_epochs = 15\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の描画\n",
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(val_losses, label='validation loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}